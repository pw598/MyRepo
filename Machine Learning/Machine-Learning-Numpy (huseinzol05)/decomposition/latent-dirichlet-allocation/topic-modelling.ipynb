{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "from scipy.special import gammaln\n",
    "import re, random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_index(p):\n",
    "    return np.random.multinomial(1,p).argmax()\n",
    "\n",
    "def word_indices(vec):\n",
    "    for idx in vec.nonzero()[0]:\n",
    "        for i in range(int(vec[idx])):\n",
    "            yield idx\n",
    "\n",
    "def log_multi_beta(alpha, K=None):\n",
    "    if K is None:\n",
    "        return np.sum(gammaln(alpha)) - gammaln(np.sum(alpha))\n",
    "    else:\n",
    "        return K * gammaln(alpha) - gammaln(K*alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LDA:\n",
    "    def __init__(self, corpus, n_topics, iteration=30, alpha=0.1, beta=0.1):\n",
    "        self.corpus = corpus\n",
    "        self.vocabulary = list(set(' '.join(self.corpus).split()))\n",
    "        self.iteration = iteration\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.n_topics = n_topics\n",
    "        self._bow()\n",
    "        n_docs, vocab_size = self.tfidf.shape\n",
    "        self.nmz = np.zeros((n_docs, n_topics))\n",
    "        self.nzw = np.zeros((n_topics, vocab_size))\n",
    "        self.nm = np.zeros(n_docs)\n",
    "        self.nz = np.zeros(self.n_topics)\n",
    "        self.topics = {}\n",
    "        \n",
    "        for m in range(n_docs):\n",
    "            for i, w in enumerate(word_indices(self.tfidf[m, :])):\n",
    "                z = np.random.randint(n_topics)\n",
    "                self.nmz[m,z] += 1\n",
    "                self.nm[m] += 1\n",
    "                self.nzw[z,w] += 1\n",
    "                self.nz[z] += 1\n",
    "                self.topics[(m,i)] = z\n",
    "        \n",
    "    def _bow(self):\n",
    "        self.tfidf = np.zeros((len(self.corpus),len(self.vocabulary)))\n",
    "        for no, i in enumerate(self.corpus):\n",
    "            for text in i.split():\n",
    "                self.tfidf[no, self.vocabulary.index(text)] += 1\n",
    "                \n",
    "    def _conditional_distribution(self, m, w):\n",
    "        vocab_size = self.nzw.shape[1]\n",
    "        left = (self.nzw[:,w] + self.beta) / (self.nz + self.beta * vocab_size)\n",
    "        right = (self.nmz[m,:] + self.alpha) / (self.nm[m] + self.alpha * self.n_topics)\n",
    "        p_z = left * right\n",
    "        p_z /= np.sum(p_z)\n",
    "        return p_z\n",
    "                \n",
    "    def loglikelihood(self):\n",
    "        vocab_size = self.nzw.shape[1]\n",
    "        n_docs = self.nmz.shape[0]\n",
    "        lik = 0\n",
    "        for z in range(self.n_topics):\n",
    "            lik += log_multi_beta(self.nzw[z,:]+self.beta)\n",
    "            lik -= log_multi_beta(self.beta, vocab_size)\n",
    "        for m in range(n_docs):\n",
    "            lik += log_multi_beta(self.nmz[m,:]+self.alpha)\n",
    "            lik -= log_multi_beta(self.alpha, self.n_topics)\n",
    "        return lik\n",
    "    \n",
    "    def run(self):\n",
    "        for it in range(self.iteration):\n",
    "            for m in range(self.tfidf.shape[0]):\n",
    "                for i, w in enumerate(word_indices(self.tfidf[m, :])):\n",
    "                    z = self.topics[(m,i)]\n",
    "                    self.nmz[m,z] -= 1\n",
    "                    self.nm[m] -= 1\n",
    "                    self.nzw[z,w] -= 1\n",
    "                    self.nz[z] -= 1\n",
    "                    p_z = self._conditional_distribution(m, w)\n",
    "                    z = sample_index(p_z)\n",
    "                    self.nmz[m,z] += 1\n",
    "                    self.nm[m] += 1\n",
    "                    self.nzw[z,w] += 1\n",
    "                    self.nz[z] += 1\n",
    "                    self.topics[(m,i)] = z\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('kerajaan','r') as fopen:\n",
    "    kerajaan = list(filter(None, fopen.read().split('\\n')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clearstring(string):\n",
    "    string = re.sub('[^A-Za-z0-9 ]+', '', string)\n",
    "    string = string.split(' ')\n",
    "    string = filter(None, string)\n",
    "    string = [y.strip() for y in string]\n",
    "    string = ' '.join(string)\n",
    "    return string.lower()\n",
    "\n",
    "kerajaan = [clearstring(i) for i in kerajaan]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_topics(corpus, count=10, k_words=10):\n",
    "    lda = LDA(corpus,k_words)\n",
    "    lda.run()\n",
    "    vectors = lda.nmz[:count] \n",
    "    top_words = lambda t: [lda.vocabulary[i] for i in np.argsort(t)[:-k_words-1:-1]]\n",
    "    topic_words = ([top_words(t) for t in vectors])\n",
    "    return [' '.join(t) for t in topic_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['buckle airbus bersepadu lawat kemalangn kongres 17rakaat ksemua menampung berliku',\n",
       " 'kemalangn buckle bersepadu lawat kongres 17rakaat ksemua menampung airbus berliku',\n",
       " 'kongres bersepadu lawat kemalangn 17rakaat buckle ksemua menampung airbus berliku',\n",
       " 'kongres bersepadu lawat kemalangn 17rakaat buckle ksemua menampung airbus berliku',\n",
       " 'menampung bersepadu lawat kemalangn kongres 17rakaat buckle ksemua airbus berliku',\n",
       " 'kemalangn buckle lawat berliku bersepadu kongres 17rakaat ksemua menampung airbus',\n",
       " 'menampung airbus bersepadu lawat kemalangn kongres 17rakaat buckle ksemua berliku',\n",
       " 'kongres bersepadu lawat kemalangn 17rakaat buckle ksemua menampung airbus berliku',\n",
       " 'ksemua kemalangn buckle airbus bersepadu lawat kongres 17rakaat menampung berliku',\n",
       " 'berliku buckle kemalangn bersepadu lawat kongres 17rakaat ksemua menampung airbus']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_topics(kerajaan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
