{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('kerajaan','r') as fopen:\n",
    "    kerajaan = list(filter(None, fopen.read().split('\\n')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clearstring(string):\n",
    "    string = re.sub('[^A-Za-z0-9 ]+', '', string)\n",
    "    string = string.split(' ')\n",
    "    string = filter(None, string)\n",
    "    string = [y.strip() for y in string]\n",
    "    string = ' '.join(string)\n",
    "    return string.lower()\n",
    "\n",
    "kerajaan = [clearstring(i) for i in kerajaan]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def penalty(M, mu):\n",
    "    return np.where(M>=mu,0, np.min(M - mu, 0))\n",
    "\n",
    "def grads(M, W, H, lam, mu):\n",
    "    R = W.dot(H) - M\n",
    "    return R.dot(H.T) + penalty(W, mu)*lam, W.T.dot(R) + penalty(H, mu)*lam\n",
    "\n",
    "def upd(M, W, H, lr, lam, mu):\n",
    "    dW,dH = grads(M,W,H,lam,mu)\n",
    "    W -= lr*dW\n",
    "    H -= lr*dH\n",
    "    \n",
    "def tfidf(corpus):\n",
    "    vocabulary = list(set(' '.join(corpus).split()))\n",
    "    idf = {}\n",
    "    for i in vocabulary:\n",
    "        idf[i] = 0\n",
    "        for k in corpus:\n",
    "            if i in k.split():\n",
    "                idf[i] += 1\n",
    "        idf[i] = np.log(idf[i] / len(corpus))\n",
    "    tfidf = np.zeros((len(corpus),len(vocabulary)))\n",
    "    for no, i in enumerate(corpus):\n",
    "        for text in i.split():\n",
    "            tfidf[no, vocabulary.index(text)] += 1\n",
    "        for text in i.split():\n",
    "            tfidf[no, vocabulary.index(text)] = tfidf[no, vocabulary.index(text)] * idf[text]\n",
    "    return vocabulary, tfidf\n",
    "\n",
    "def bow(corpus):\n",
    "    vocabulary = list(set(' '.join(corpus).split()))\n",
    "    bow = np.zeros((len(corpus),len(vocabulary)))\n",
    "    for no, i in enumerate(corpus):\n",
    "        for text in i.split():\n",
    "            bow[no, vocabulary.index(text)] += 1\n",
    "    return vocabulary, bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_topics(corpus, count=10, k_words=10, use_tfidf=True, penalty=1e-6, learning_rate=1e-6,\n",
    "               lam=1e3,epoch=50):\n",
    "    if use_tfidf:\n",
    "        vocab, vectors = tfidf(corpus)\n",
    "    else:\n",
    "        vocab, vectors = bow(corpus)\n",
    "    print('vectors shape:',vectors.shape)\n",
    "    m, n = vectors.shape\n",
    "    W = np.abs(np.random.normal(scale=0.01, size=(m,count)))\n",
    "    H = np.abs(np.random.normal(scale=0.01, size=(count,n)))\n",
    "    for i in range(epoch):\n",
    "        upd(vectors,W,H,learning_rate,lam,penalty)\n",
    "        print('epoch:',i, W.min(), H.min())\n",
    "    top_words = lambda t: [vocab[i] for i in np.argsort(t)[:-k_words-1:-1]]\n",
    "    topic_words = ([top_words(t) for t in H])\n",
    "    return [' '.join(t) for t in topic_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vectors shape: (6957, 16212)\n",
      "epoch: 0 -4.1044924381583935e-07 -2.90772193167458e-06\n",
      "epoch: 1 -7.8695576390063e-06 -6.253696457086038e-06\n",
      "epoch: 2 -3.4228037418379374e-05 -9.596089298466051e-06\n",
      "epoch: 3 -6.055980410656732e-05 -1.3333561301495036e-05\n",
      "epoch: 4 -8.686499916818119e-05 -2.0944640100188828e-05\n",
      "epoch: 5 -0.00011314376380983153 -2.8547641497971757e-05\n",
      "epoch: 6 -0.00013939623898103027 -3.6142573639530124e-05\n",
      "epoch: 7 -0.00016562256537509216 -4.3729444662373384e-05\n",
      "epoch: 8 -0.0001918228834300349 -5.130826269686379e-05\n",
      "epoch: 9 -0.00021799733332947895 -5.887903586627732e-05\n",
      "epoch: 10 -0.0002441460550035473 -6.64417722868597e-05\n",
      "epoch: 11 -0.00027026918812976373 -7.39964800678866e-05\n",
      "epoch: 12 -0.0002963668721339562 -8.154316731171842e-05\n",
      "epoch: 13 -0.00032243924619115133 -8.908184211389151e-05\n",
      "epoch: 14 -0.0003484864492264663 -9.661251256313463e-05\n",
      "epoch: 15 -0.0003745086199160063 -0.00010413518674145421\n",
      "epoch: 16 -0.0004005058966877604 -0.00011164987272422302\n",
      "epoch: 17 -0.0004264784177225016 -0.0001279288940378729\n",
      "epoch: 18 -0.00045242632095455104 -0.00017022687973194478\n",
      "epoch: 19 -0.00047834974407267184 -0.00021248205910133673\n",
      "epoch: 20 -0.0005042488245209668 -0.0002546946584620727\n",
      "epoch: 21 -0.000530123699499772 -0.00029686490371796215\n",
      "epoch: 22 -0.0005559745059665528 -0.00033899302036178805\n",
      "epoch: 23 -0.0005818013806368022 -0.000381079233476807\n",
      "epoch: 24 -0.0006076044599849372 -0.0004231237677380898\n",
      "epoch: 25 -0.0006333838802451981 -0.0004651268474141948\n",
      "epoch: 26 -0.0006591397774125548 -0.0005070886963683779\n",
      "epoch: 27 -0.0006848722872435997 -0.0005490095380599262\n",
      "epoch: 28 -0.0007105815452574472 -0.0005908895955454773\n",
      "epoch: 29 -0.0007362676867366378 -0.0006327290914810896\n",
      "epoch: 30 -0.0007619308467280407 -0.0006745282481228718\n",
      "epoch: 31 -0.0007875711600437581 -0.000716287287328728\n",
      "epoch: 32 -0.0008173509272152328 -0.000758006430559504\n",
      "epoch: 33 -0.0008513582303096573 -0.0007996858988820443\n",
      "epoch: 34 -0.0008853325305552274 -0.0008413259129674747\n",
      "epoch: 35 -0.0009192739276010804 -0.0008829266930953532\n",
      "epoch: 36 -0.0009531825209330819 -0.0009244884591534525\n",
      "epoch: 37 -0.0009870584098742618 -0.0009660114306396433\n",
      "epoch: 38 -0.0010209016935852234 -0.001007495826662702\n",
      "epoch: 39 -0.00105471247106459 -0.0010489418659462102\n",
      "epoch: 40 -0.0010884908411494078 -0.0010903497668260733\n",
      "epoch: 41 -0.0011222369025156147 -0.0011317197472553127\n",
      "epoch: 42 -0.001155950753678441 -0.0011730520248030844\n",
      "epoch: 43 -0.0011896324929928487 -0.0012143468166576255\n",
      "epoch: 44 -0.0012232822186539999 -0.0012556043396279525\n",
      "epoch: 45 -0.0012569000286976662 -0.0012968248101398491\n",
      "epoch: 46 -0.001290486021000694 -0.0013380084442423039\n",
      "epoch: 47 -0.0013240402932814404 -0.0013791554576082045\n",
      "epoch: 48 -0.0013575629431002358 -0.0014202660655350163\n",
      "epoch: 49 -0.0013910540678598402 -0.001461340482947894\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['jpm acucomei tilawah aadkkedah singapore mnjadi matches gerus support sukacita',\n",
       " 'yef2016 chill bersinar saudara2 episod harmed rm26j pu3uampang bnm blake',\n",
       " 'cth peneraju two pemandngan fasal meru witnessing petrol tersebut triples',\n",
       " 'theyve buloh merbokjaguar nasionalfm wawrinka kepada harithiskander exert providing rencana',\n",
       " 'bistro prktanjongdatu betul ringankan pilatus pergigian february bakul ayaq rai',\n",
       " 'airforcenextgen peneraju beijingtianjin gulai perkuburan jwtn ummah sibu dvm funding',\n",
       " 'peneraju cleanliness stiap ahead lembu pangkalan beserta computers insan denyutan',\n",
       " 'almari 754 cities programs 132 penyelenggaraan penerangan totally vivekananda simptom',\n",
       " 'declaration 012017 akademi jkpd card perlis ditetapkan 4852 dipandu sai',\n",
       " 'padi tudung didahului herman mbm jannahhishammuddinh2o tapah hartanah sebat jadilah']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_topics(kerajaan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
