{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import sklearn.datasets\n",
    "import re\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clearstring(string):\n",
    "    string = re.sub('[^A-Za-z0-9 ]+', '', string)\n",
    "    string = string.split(' ')\n",
    "    string = filter(None, string)\n",
    "    string = [y.strip() for y in string]\n",
    "    string = ' '.join(string)\n",
    "    return string\n",
    "\n",
    "def separate_dataset(trainset):\n",
    "    datastring = []\n",
    "    datatarget = []\n",
    "    for i in range(len(trainset.data)):\n",
    "        data_ = trainset.data[i].split('\\n')\n",
    "        data_ = list(filter(None, data_))\n",
    "        for n in range(len(data_)):\n",
    "            data_[n] = clearstring(data_[n])\n",
    "        datastring += data_\n",
    "        for n in range(len(data_)):\n",
    "            datatarget.append(trainset.target[i])\n",
    "    return datastring, datatarget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['kerajaan', 'pembangkang']\n",
      "201\n",
      "201\n"
     ]
    }
   ],
   "source": [
    "trainset = sklearn.datasets.load_files(container_path = 'local', encoding = 'UTF-8')\n",
    "trainset.data, trainset.target = separate_dataset(trainset)\n",
    "print (trainset.target_names)\n",
    "print (len(trainset.data))\n",
    "print (len(trainset.target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1737"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary = list(set(' '.join(trainset.data).split()))\n",
    "len(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate IDF\n",
    "idf = {}\n",
    "for i in vocabulary:\n",
    "    idf[i] = 0\n",
    "    for k in trainset.data:\n",
    "        if i in k.split():\n",
    "            idf[i] += 1\n",
    "    idf[i] = np.log(idf[i] / len(trainset.data))\n",
    "\n",
    "# calculate TF\n",
    "X = np.zeros((len(trainset.data),len(vocabulary)))\n",
    "for no, i in enumerate(trainset.data):\n",
    "    for text in i.split():\n",
    "        X[no, vocabulary.index(text)] += 1\n",
    "    for text in i.split():\n",
    "        # calculate TF * IDF\n",
    "        X[no, vocabulary.index(text)] = X[no, vocabulary.index(text)] * idf[text]\n",
    "        \n",
    "X = np.abs(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, test_X, train_Y, test_Y = train_test_split(X, trainset.target, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianNB:\n",
    "    def __init__(self, epsilon):\n",
    "        self.EPSILON = epsilon\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        separated = [[x for x, t in zip(X, y) if t == c] for c in np.unique(y)]\n",
    "        self.model = np.array([np.c_[np.mean(i, axis=0)+self.EPSILON, np.std(i, axis=0)+self.EPSILON] for i in separated])\n",
    "\n",
    "    def _prob(self, x, mean, std):\n",
    "        exponent = np.exp(-((x - mean)**2 / (2 * std**2))+self.EPSILON)\n",
    "        return np.log((exponent / (np.sqrt(2 * np.pi) * std))+self.EPSILON)\n",
    "\n",
    "    def predict_log_proba(self, X):\n",
    "        log_proba = [[sum(self._prob(i, *s) for s, i in zip(summaries, x)) for summaries in self.model] for x in X]\n",
    "        return [i/np.sum(i) for i in log_proba]\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.argmax(self.predict_log_proba(X), axis=1)\n",
    "\n",
    "    def score(self, X, y):\n",
    "        return sum(self.predict(X) == y) / len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaussian_bayes = GaussianNB(1e-8)\n",
    "gaussian_bayes.fit(train_X, train_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## accuracy training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48125"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gaussian_bayes.score(train_X, train_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## accuracy testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5853658536585366"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gaussian_bayes.score(test_X, test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.39327101, 0.60672899]),\n",
       " array([0.39263689, 0.60736311]),\n",
       " array([0.39179131, 0.60820869]),\n",
       " array([0.38721061, 0.61278939]),\n",
       " array([0.38833738, 0.61166262]),\n",
       " array([0.38840505, 0.61159495]),\n",
       " array([0.38683972, 0.61316028]),\n",
       " array([0.39020765, 0.60979235]),\n",
       " array([0.39029644, 0.60970356]),\n",
       " array([0.38749508, 0.61250492]),\n",
       " array([0.39025201, 0.60974799]),\n",
       " array([0.39241201, 0.60758799]),\n",
       " array([0.38840757, 0.61159243]),\n",
       " array([0.38883126, 0.61116874]),\n",
       " array([0.38506275, 0.61493725]),\n",
       " array([0.38782718, 0.61217282]),\n",
       " array([0.38773943, 0.61226057]),\n",
       " array([0.38692275, 0.61307725]),\n",
       " array([0.38791895, 0.61208105]),\n",
       " array([0.38972045, 0.61027955]),\n",
       " array([0.3915118, 0.6084882]),\n",
       " array([0.38675418, 0.61324582]),\n",
       " array([0.39001741, 0.60998259]),\n",
       " array([0.38830252, 0.61169748]),\n",
       " array([0.38751443, 0.61248557]),\n",
       " array([0.38995648, 0.61004352]),\n",
       " array([0.39218534, 0.60781466]),\n",
       " array([0.38756023, 0.61243977]),\n",
       " array([0.38868535, 0.61131465]),\n",
       " array([0.38685803, 0.61314197]),\n",
       " array([0.38969438, 0.61030562]),\n",
       " array([0.38578901, 0.61421099]),\n",
       " array([0.39198005, 0.60801995]),\n",
       " array([0.39017483, 0.60982517]),\n",
       " array([0.39052678, 0.60947322]),\n",
       " array([0.389118, 0.610882]),\n",
       " array([0.38837263, 0.61162737]),\n",
       " array([0.39055565, 0.60944435]),\n",
       " array([0.39049296, 0.60950704]),\n",
       " array([0.38975943, 0.61024057]),\n",
       " array([0.38621536, 0.61378464])]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gaussian_bayes.predict_log_proba(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
